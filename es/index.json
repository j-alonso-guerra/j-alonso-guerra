[{"categories":["Golang","Concurrencia"],"contents":"Si has trabajado con Go por algún tiempo, probablemente llegaste al punto donde lanzar una goroutine por tarea empieza a sentirse mal. Quizás estás golpeando rate limits de APIs, agotando conexiones de base de datos, o simplemente viendo cómo tu uso de memoria escala sin control. Ahí es donde entran los worker pools.\nUn worker pool es un patrón de concurrencia donde un número fijo de goroutines (workers) procesan tareas desde una cola compartida. Te da paralelismo controlado — la capacidad de hacer muchas cosas a la vez sin hacer todo a la vez.\n¿Por qué Worker Pools? Considera este enfoque ingenuo:\n1 2 3 for _, url := range urls { go fetch(url) // 10,000 URLs = 10,000 goroutines } Esto funciona hasta que deja de hacerlo. Con 10,000 URLs abrirás 10,000 conexiones simultáneas, probablemente recibiendo rate-limit, quedándote sin file descriptors, o tumbando el servidor destino.\nUn worker pool resuelve esto limitando la concurrencia:\n1 2 3 4 5 ┌──────────┐ Tareas ─\u0026gt;│ Channel │──\u0026gt; Worker 1 ──\u0026gt; Resultados │ (Cola) │──\u0026gt; Worker 2 ──\u0026gt; Resultados │ │──\u0026gt; Worker 3 ──\u0026gt; Resultados └──────────┘ Workers fijos, throughput controlado, uso de recursos predecible.\nEl Patrón Básico El worker pool más simple en Go:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func worker(id int, jobs \u0026lt;-chan int, results chan\u0026lt;- int, wg *sync.WaitGroup) { defer wg.Done() for job := range jobs { fmt.Printf(\u0026#34;Worker %d procesando job %d\\n\u0026#34;, id, job) results \u0026lt;- job * 2 } } func main() { const numWorkers = 3 const numJobs = 10 jobs := make(chan int, numJobs) results := make(chan int, numJobs) var wg sync.WaitGroup // Iniciar workers for i := 1; i \u0026lt;= numWorkers; i++ { wg.Add(1) go worker(i, jobs, results, \u0026amp;wg) } // Enviar jobs for j := 1; j \u0026lt;= numJobs; j++ { jobs \u0026lt;- j } close(jobs) // Esperar y cerrar resultados go func() { wg.Wait() close(results) }() // Recolectar resultados for result := range results { fmt.Println(\u0026#34;Resultado:\u0026#34;, result) } } Desglosemos las piezas clave:\nCanal jobs — la cola. Los workers leen de él, el productor escribe en él. Canal results — donde los workers envían su output. sync.WaitGroup — rastrea cuándo todos los workers terminaron. close(jobs) — señala a los workers que no hay más trabajo. El loop range termina. Esta es la base. Todo lo demás se construye sobre esto.\nAgregando Manejo de Errores Las tareas del mundo real fallan. Necesitas una forma de propagar errores de vuelta sin perderlos:\n1 2 3 4 5 6 7 8 9 10 11 12 type Result struct { Value int Err error } func worker(id int, jobs \u0026lt;-chan int, results chan\u0026lt;- Result, wg *sync.WaitGroup) { defer wg.Done() for job := range jobs { val, err := process(job) results \u0026lt;- Result{Value: val, Err: err} } } Ahora el consumidor puede verificar cada resultado:\n1 2 3 4 5 6 7 for r := range results { if r.Err != nil { log.Printf(\u0026#34;job falló: %v\u0026#34;, r.Err) continue } fmt.Println(\u0026#34;Éxito:\u0026#34;, r.Value) } Graceful Shutdown con Context En producción, necesitas detener workers limpiamente — ante SIGTERM, timeout, o cuando ocurre un error crítico. context.Context es la forma estándar:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func worker(ctx context.Context, id int, jobs \u0026lt;-chan Job, results chan\u0026lt;- Result, wg *sync.WaitGroup) { defer wg.Done() for { select { case \u0026lt;-ctx.Done(): fmt.Printf(\u0026#34;Worker %d: apagando\\n\u0026#34;, id) return case job, ok := \u0026lt;-jobs: if !ok { return } results \u0026lt;- process(job) } } } El caller controla el ciclo de vida:\n1 2 3 4 5 6 7 8 9 10 ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second) defer cancel() // Ante señal de interrupción go func() { sigCh := make(chan os.Signal, 1) signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-sigCh cancel() }() Cuando se llama cancel(), el ctx.Done() de cada worker se dispara y salen limpiamente. Sin goroutines fugadas, sin trabajo a medio procesar.\nUn Pool Listo para Producción Juntemos todo en una estructura reutilizable:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 package pool import ( \u0026#34;context\u0026#34; \u0026#34;sync\u0026#34; ) type Task[T any, R any] struct { Payload T } type Result[R any] struct { Value R Err error } type Pool[T any, R any] struct { workers int handler func(context.Context, T) (R, error) jobs chan Task[T, R] results chan Result[R] } func New[T any, R any](workers, queueSize int, handler func(context.Context, T) (R, error)) *Pool[T, R] { return \u0026amp;Pool[T, R]{ workers: workers, handler: handler, jobs: make(chan Task[T, R], queueSize), results: make(chan Result[R], queueSize), } } func (p *Pool[T, R]) Start(ctx context.Context) { var wg sync.WaitGroup for i := 0; i \u0026lt; p.workers; i++ { wg.Add(1) go func() { defer wg.Done() for { select { case \u0026lt;-ctx.Done(): return case task, ok := \u0026lt;-p.jobs: if !ok { return } val, err := p.handler(ctx, task.Payload) p.results \u0026lt;- Result[R]{Value: val, Err: err} } } }() } go func() { wg.Wait() close(p.results) }() } func (p *Pool[T, R]) Submit(task Task[T, R]) { p.jobs \u0026lt;- task } func (p *Pool[T, R]) Close() { close(p.jobs) } func (p *Pool[T, R]) Results() \u0026lt;-chan Result[R] { return p.results } El uso es limpio:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() p := pool.New[string, int](5, 100, func(ctx context.Context, url string) (int, error) { resp, err := http.Get(url) if err != nil { return 0, err } defer resp.Body.Close() return resp.StatusCode, nil }) p.Start(ctx) urls := []string{\u0026#34;https://go.dev\u0026#34;, \u0026#34;https://github.com\u0026#34;, \u0026#34;https://google.com\u0026#34;} for _, u := range urls { p.Submit(pool.Task[string, int]{Payload: u}) } p.Close() for r := range p.Results() { if r.Err != nil { log.Printf(\u0026#34;Error: %v\u0026#34;, r.Err) continue } fmt.Printf(\u0026#34;Status: %d\\n\u0026#34;, r.Value) } } Cuándo Usar Worker Pools Escenario Tamaño sugerido del Pool Llamadas HTTP con rate limits Igualar el rate limit Operaciones batch de base de datos Igualar el connection pool Procesamiento CPU-bound (resize de imágenes, hashing) runtime.NumCPU() Operaciones de File I/O 2x-4x conteo de CPUs Cargas mixtas Perfilar y ajustar Conclusiones Clave No lances goroutines sin límite — usa un pool para controlar la concurrencia. Siempre usa context.Context — es el mecanismo estándar de cancelación en Go. Channels con buffer para la cola de jobs evitan que el productor se bloquee. sync.WaitGroup + close() es la forma más limpia de señalar completitud. Generics (Go 1.18+) hacen que los pools reutilizables sean prácticos sin casting de interface{}. Los worker pools son uno de esos patrones que parecen simples pero desbloquean poder serio cuando construyes sistemas a escala. Empieza con el patrón básico, agrega manejo de errores, conecta context para graceful shutdown, y tienes un building block listo para producción.\n¿Te fue útil? Revisa mis otros posts sobre patrones de concurrencia en Go.\n","permalink":"/es/post/2026-02-14-golang-worker-pools/","tags":["golang","worker-pools","concurrencia","channels","goroutines"],"title":"Dominando Worker Pools en Go: Guía Práctica"},{"categories":null,"contents":"Hey! Soy J. Alonso Guerra, ingeniero backend colombiano. Llevo varios años construyendo sistemas distribuidos y aplicaciones cloud-native con Go.\nMe apasiona diseñar sistemas que manejen escala real — desde plataformas de mensajería que procesan millones de interacciones diarias hasta motores de facturación con procesamiento de eventos en tiempo real. Disfruto el reto de hacer las cosas rápidas, confiables y elegantes por dentro.\nQué hago Actualmente trabajo como Senior Backend Engineer en Ipcom, donde diseño arquitecturas event-driven en GCP, construyo sistemas de reportes en tiempo real y lidero el desarrollo backend de plataformas de voicebot con IA. Antes de eso, trabajé en modernización de microservicios para Falabella (uno de los retailers más grandes de Latinoamérica) y construí plataformas de seguridad digital en Virtual Padlock.\nMi toolkit diario gira en torno a Go, Kubernetes, Redis, NATS, y plataformas cloud como GCP y AWS. Creo firmemente en clean architecture, domain-driven design, y mantener las cosas simples hasta que la complejidad sea realmente necesaria.\nMás allá del código Cuando no estoy escribiendo Go, me encuentras explorando certificaciones cloud, experimentando con agentes de IA, o leyendo sobre patrones de diseño de sistemas. Hablo español nativo e inglés profesional — he trabajado remotamente con equipos en Colombia, Chile, Perú y más.\nConectemos LinkedIn GitHub juniorguerrac17@gmail.com ","permalink":"/es/about/","tags":null,"title":"Acerca de"},{"categories":null,"contents":"","permalink":"/es/archives/","tags":null,"title":"Archivo"}]
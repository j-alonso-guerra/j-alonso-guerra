[{"categories":["Golang","Concurrency"],"contents":"If you\u0026rsquo;ve worked with Go for any amount of time, you\u0026rsquo;ve probably reached a point where spinning up a goroutine per task starts to feel wrong. Maybe you\u0026rsquo;re hitting API rate limits, exhausting database connections, or just watching your memory usage climb. That\u0026rsquo;s where worker pools come in.\nA worker pool is a concurrency pattern where a fixed number of goroutines (workers) process tasks from a shared queue. It gives you controlled parallelism — the ability to do many things at once without doing everything at once.\nWhy Worker Pools? Consider this naive approach:\n1 2 3 for _, url := range urls { go fetch(url) // 10,000 URLs = 10,000 goroutines } This works until it doesn\u0026rsquo;t. With 10,000 URLs you\u0026rsquo;ll open 10,000 connections simultaneously, likely getting rate-limited, running out of file descriptors, or crashing the target server.\nA worker pool solves this by limiting concurrency:\n1 2 3 4 5 ┌──────────┐ Tasks ──\u0026gt;│ Channel │──\u0026gt; Worker 1 ──\u0026gt; Results │ (Queue) │──\u0026gt; Worker 2 ──\u0026gt; Results │ │──\u0026gt; Worker 3 ──\u0026gt; Results └──────────┘ Fixed workers, controlled throughput, predictable resource usage.\nThe Basic Pattern Here\u0026rsquo;s the simplest worker pool in Go:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func worker(id int, jobs \u0026lt;-chan int, results chan\u0026lt;- int, wg *sync.WaitGroup) { defer wg.Done() for job := range jobs { fmt.Printf(\u0026#34;Worker %d processing job %d\\n\u0026#34;, id, job) results \u0026lt;- job * 2 } } func main() { const numWorkers = 3 const numJobs = 10 jobs := make(chan int, numJobs) results := make(chan int, numJobs) var wg sync.WaitGroup // Start workers for i := 1; i \u0026lt;= numWorkers; i++ { wg.Add(1) go worker(i, jobs, results, \u0026amp;wg) } // Send jobs for j := 1; j \u0026lt;= numJobs; j++ { jobs \u0026lt;- j } close(jobs) // Wait and close results go func() { wg.Wait() close(results) }() // Collect results for result := range results { fmt.Println(\u0026#34;Result:\u0026#34;, result) } } Let\u0026rsquo;s break down the key pieces:\njobs channel — the queue. Workers read from it, the producer writes to it. results channel — where workers send their output. sync.WaitGroup — tracks when all workers are done. close(jobs) — signals workers there\u0026rsquo;s no more work. The range loop exits. This is the foundation. Everything else builds on top of it.\nAdding Error Handling Real-world tasks fail. You need a way to propagate errors back without losing them:\n1 2 3 4 5 6 7 8 9 10 11 12 type Result struct { Value int Err error } func worker(id int, jobs \u0026lt;-chan int, results chan\u0026lt;- Result, wg *sync.WaitGroup) { defer wg.Done() for job := range jobs { val, err := process(job) results \u0026lt;- Result{Value: val, Err: err} } } Now the consumer can check each result:\n1 2 3 4 5 6 7 for r := range results { if r.Err != nil { log.Printf(\u0026#34;job failed: %v\u0026#34;, r.Err) continue } fmt.Println(\u0026#34;Success:\u0026#34;, r.Value) } Graceful Shutdown with Context In production, you need to stop workers cleanly — on SIGTERM, on timeout, or when a critical error occurs. context.Context is the standard way:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func worker(ctx context.Context, id int, jobs \u0026lt;-chan Job, results chan\u0026lt;- Result, wg *sync.WaitGroup) { defer wg.Done() for { select { case \u0026lt;-ctx.Done(): fmt.Printf(\u0026#34;Worker %d: shutting down\\n\u0026#34;, id) return case job, ok := \u0026lt;-jobs: if !ok { return } results \u0026lt;- process(job) } } } The caller controls the lifecycle:\n1 2 3 4 5 6 7 8 9 10 ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second) defer cancel() // On interrupt signal go func() { sigCh := make(chan os.Signal, 1) signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-sigCh cancel() }() When cancel() is called, every worker\u0026rsquo;s ctx.Done() fires and they exit gracefully. No leaked goroutines, no half-processed work.\nA Production-Ready Pool Let\u0026rsquo;s put it all together into a reusable structure:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 package pool import ( \u0026#34;context\u0026#34; \u0026#34;sync\u0026#34; ) type Task[T any, R any] struct { Payload T } type Result[R any] struct { Value R Err error } type Pool[T any, R any] struct { workers int handler func(context.Context, T) (R, error) jobs chan Task[T, R] results chan Result[R] } func New[T any, R any](workers, queueSize int, handler func(context.Context, T) (R, error)) *Pool[T, R] { return \u0026amp;Pool[T, R]{ workers: workers, handler: handler, jobs: make(chan Task[T, R], queueSize), results: make(chan Result[R], queueSize), } } func (p *Pool[T, R]) Start(ctx context.Context) { var wg sync.WaitGroup for i := 0; i \u0026lt; p.workers; i++ { wg.Add(1) go func() { defer wg.Done() for { select { case \u0026lt;-ctx.Done(): return case task, ok := \u0026lt;-p.jobs: if !ok { return } val, err := p.handler(ctx, task.Payload) p.results \u0026lt;- Result[R]{Value: val, Err: err} } } }() } go func() { wg.Wait() close(p.results) }() } func (p *Pool[T, R]) Submit(task Task[T, R]) { p.jobs \u0026lt;- task } func (p *Pool[T, R]) Close() { close(p.jobs) } func (p *Pool[T, R]) Results() \u0026lt;-chan Result[R] { return p.results } Usage is clean:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func main() { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() p := pool.New[string, int](5, 100, func(ctx context.Context, url string) (int, error) { resp, err := http.Get(url) if err != nil { return 0, err } defer resp.Body.Close() return resp.StatusCode, nil }) p.Start(ctx) urls := []string{\u0026#34;https://go.dev\u0026#34;, \u0026#34;https://github.com\u0026#34;, \u0026#34;https://google.com\u0026#34;} for _, u := range urls { p.Submit(pool.Task[string, int]{Payload: u}) } p.Close() for r := range p.Results() { if r.Err != nil { log.Printf(\u0026#34;Error: %v\u0026#34;, r.Err) continue } fmt.Printf(\u0026#34;Status: %d\\n\u0026#34;, r.Value) } } When to Use Worker Pools Scenario Pool Size Hint HTTP API calls with rate limits Match the rate limit Database batch operations Match connection pool size CPU-bound processing (image resize, hashing) runtime.NumCPU() File I/O operations 2x-4x CPU count Mixed workloads Profile and tune Key Takeaways Don\u0026rsquo;t spawn unbounded goroutines — use a pool to control concurrency. Always use context.Context — it\u0026rsquo;s the standard cancellation mechanism in Go. Buffered channels for the job queue prevent the producer from blocking. sync.WaitGroup + close() is the cleanest way to signal completion. Generics (Go 1.18+) make reusable pools practical without interface{} casting. Worker pools are one of those patterns that look simple but unlock serious power when building systems at scale. Start with the basic pattern, add error handling, wire in context for graceful shutdown, and you\u0026rsquo;ve got a production-ready building block.\nFound this useful? Check out my other posts on Go concurrency patterns.\n","permalink":"/post/2026-02-14-golang-worker-pools/","tags":["golang","worker-pools","concurrency","channels","goroutines"],"title":"Mastering Worker Pools in Go: A Practical Guide"},{"categories":null,"contents":"Hey! I\u0026rsquo;m J. Alonso Guerra, a backend engineer from Colombia who\u0026rsquo;s been building distributed systems and cloud-native applications with Go for the past few years.\nI\u0026rsquo;m passionate about designing systems that handle real scale — from messaging platforms processing millions of daily interactions to billing engines with real-time event processing. I enjoy the challenge of making things fast, reliable, and elegant under the hood.\nWhat I do I currently work as a Senior Backend Engineer at Ipcom, where I design event-driven architectures on GCP, build real-time reporting systems, and lead the backend development of AI-powered voicebot platforms. Before that, I worked on microservices modernization for Falabella (one of Latin America\u0026rsquo;s largest retailers) and built digital security platforms at Virtual Padlock.\nMy daily toolkit revolves around Go, Kubernetes, Redis, NATS, and cloud platforms like GCP and AWS. I\u0026rsquo;m a firm believer in clean architecture, domain-driven design, and keeping things simple until complexity is truly needed.\nBeyond code When I\u0026rsquo;m not writing Go, you\u0026rsquo;ll find me exploring cloud certifications, tinkering with AI agents, or reading about system design patterns. I\u0026rsquo;m also a native Spanish speaker with professional English — I\u0026rsquo;ve worked remotely with teams across Colombia, Chile, Peru, and beyond.\nLet\u0026rsquo;s connect LinkedIn GitHub juniorguerrac17@gmail.com ","permalink":"/about/","tags":null,"title":"About"},{"categories":null,"contents":"","permalink":"/archives/","tags":null,"title":"Archives"}]